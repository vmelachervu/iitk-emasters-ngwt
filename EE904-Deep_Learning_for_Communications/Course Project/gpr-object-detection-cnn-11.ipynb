{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1CsFLMRRq1fLRm8xDAgEfriyt_LtI-eBK","timestamp":1708879408694}],"gpuType":"V100","mount_file_id":"1UJximCraOGQDxuR_T2k06TjcHhVMN3hS","authorship_tag":"ABX9TyNBupjw6dddaHkRyrWM56Sw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Course Project - Object Detection Using CNNs in RADAR Signal Imagery  \n","\n","Course Name: EE904 - Deep Learning For Wireless Communication   \n","Professor: Prof. Tushar Sandhan  \n","Academic Quarter: Q3-2023-2024  \n","Author and Student Name: Venkateswar Reddy Melachervu  \n","Roll No: 23156022  \n","Email: vmela23@iitk.ac.in  \n","  \n","**Project Description**  \n","The principal objective of this project is to classify, using deep neural network, a given/unseen RADAR signal imagery obtained from the RADAR scan of a wall accurately into:  \n",">***Empty***: *No person behind the wall*  \n",">***Still***: *A person is present behind the wall in stand-still position*  \n",">***Walking***: *A person is walking behind the wall*  \n","\n","This scenario finds crucial application in military endeavors and surveillance.\n","\n","**Training Dataset**  \n","Training data set of RADAR scan imagery taken through a concrete wall is provided as input to this project and was made available at [this link](https://drive.google.com/drive/folders/1g5NS45zaoxXOran9CYM8J49tTyhZ_9Hd). The dataset contains train folder with sample imagery for training the deep network and test folder with test magery to evaluate the performance of the developed network model.  \n","\n","**Program Tasks**  \n","The main task is to investigate/classify the RADAR signal imagery accurately for the object behind the wall - empty, person standing still or walking. Additionally, this project investigates higher accuracy CNN model, using trial and error method, for this classification while addressing the below requirements of the project assignment.\n","1.   Plots 5 random images from each class on a single row and details an intuitive human analysis of imagery patterns to manually classify any new sample into one of the three classes - *Empty, Still, Walking*\n","2.   Selects 10 samples randomly from each class, mixes them all up for manual classification and creates a report on the correct classification and difficulties faced for in-correct classification.\n","3.   Uses non-CNN MLP NN for training and testing and creates a report on accuracy, training time, accuracy graphs\n","4.   Designs and uses a CNN with 1 hidden layer and trains it on provided training data and creates a report on accuracy vs epoch (graphs), model details, total number of learnable parameters, training time per epoch etc.\n","5.   Evaluates the above trained CNN model with the test data set and creates a report on accuracy and plots confusion matrix.\n","6.   Designs CNN with multiple hidden layers and creates a report on accuracy vs epoch (graphs), model details, total number of learnable parameters, training time per epoch etc.\n","7.   Changes number of hidden layers, number of kernels and creates a report on accuracy vs epoch (graphs), model details, total number of learnable parameters, training time per epoch etc.\n","8.   Uses pre-trained ResNet model and creates a report on accuracy vs epoch (graphs), model details, total number of learnable parameters, training time per epoch etc.\n","\n","**Dependencies**  \n","This project leverages the below libraries:  \n",">1  Tensorflow  \n",">2  Keras  \n",">3  ResNet  \n",">4  gdown  \n",">5  PIL  \n",">6  numpy  \n",">7  google drive for training test data set etc.\n","\n","**References**  \n","\n","**Additional Information**  \n"],"metadata":{"id":"XZvxWkQwjhuT"}},{"cell_type":"code","source":["# let's do the imports and initializations and installs\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import PIL\n","import tensorflow as tf\n","import time\n","import numpy as np\n","import os\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from tensorflow import keras\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from google.colab import drive\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# configure the train and test data directory\n","train_dir = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/train'\n","train_dir_empty = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/train/empty'\n","train_dir_still = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/train/still'\n","train_dir_walking = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/train/walking'\n","val_dir = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/val/'\n","tests_dir = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/tests/'\n","tests_dir_empty = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/tests/empty'\n","tests_dir_still = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/tests/still'\n","tests_dir_walking = '/content/drive/MyDrive/EE-904-GPR-CNN-Project/dataset/tests/walking'\n","\n","# load the training samples from training data dir\n","import pathlib\n","data_dir = pathlib.Path(train_dir)\n","tests_dir = pathlib.Path(tests_dir)\n","val_dir = pathlib.Path(val_dir)"],"metadata":{"id":"wy5Kzc_UkWJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sanity checks for test/validation folder contents\n","files = os.listdir(train_dir)\n","print('Files/dirs in '+ str(train_dir) + ':' + str(files))\n","files = os.listdir(tests_dir)\n","print('Files/dirs in '+ str(tests_dir) + ':' + str(files))\n","\n","# sanity check for training data\n","images = list(data_dir.glob('*/*.jpg'))\n","image_count = len(images)\n","print('Count of images in ' + str(data_dir) + ':' + str(image_count))\n","empty = list(data_dir.glob('empty/*'))\n","empty_image_count = len(empty)\n","print('\\\"empty\\\" class training image sample count' + ':' + str(empty_image_count))\n","print('Displaying a training image in \\\"empty\\\" class...')\n","PIL.Image.open(str(empty[0]))\n","\n","# sanity check for training data\n","still = list(data_dir.glob('still/*'))\n","still_image_count = len(still)\n","print('\\\"still\\\" class training image sample count' + ':' + str(still_image_count))\n","print('Displaying a training image in \\\"still\\\" class...')\n","PIL.Image.open(str(still[0]))\n","\n","# sanity check for training data\n","walking = list(data_dir.glob('walking/*'))\n","walking_image_count = len(still)\n","print('\\\"walking\\\" class training image sample count' + ':' + str(walking_image_count))\n","print('Displaying a training image in \\\"walking\\\" class...')\n","PIL.Image.open(str(walking[0]))\n","\n","# sanity check for tests data\n","images = list(tests_dir.glob('*/*.jpg'))\n","image_count = len(images)\n","print('Count of all images in ' + str(tests_dir) + ':' + str(image_count))\n","empty = list(tests_dir.glob('empty/*'))\n","empty_image_count = len(empty)\n","print('\\\"empty\\\" class test image sample count' + ':' + str(empty_image_count))\n","print('Displaying a test image in \\\"empty\\\" class...')\n","PIL.Image.open(str(empty[0]))\n","\n","# sanity check for validation data\n","images = list(val_dir.glob('*/*.jpg'))\n","image_count = len(images)\n","print('Count of images in ' + str(val_dir) + ':' + str(image_count))\n","empty = list(val_dir.glob('empty/*'))\n","empty_image_count = len(empty)\n","print('\\\"empty\\\" class validation image sample count' + ':' + str(empty_image_count))\n","print('Displaying a validation image in \\\"empty\\\" class...')\n","PIL.Image.open(str(empty[0]))\n","\n","# Displaying 5 random images of Empty class in a row from training data set\n","from PIL import Image\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","\n","def display_random_images(directory, image_width, image_height):\n","    plt.figure(figsize=(image_width, image_height))\n","    plt.suptitle('5 Empty Class Random Training Samples', fontsize=12)\n","    image_files = os.listdir(directory)\n","    random.shuffle(image_files)\n","    for i in range(5):\n","        img_path = os.path.join(directory, image_files[i])\n","        img = Image.open(img_path)\n","        plt.subplot(1, 5, i+1)\n","        plt.imshow(img, cmap='gray')  # Specify colormap as 'gray' for grayscale images\n","        plt.title(image_files[i], fontsize=10)\n","        plt.axis('off')\n","    plt.tight_layout()  # Adjust layout to prevent overlap\n","    plt.show()\n","\n","# Display from \"Empty\" training directory\n","directory = train_dir_empty\n","image_width = 8  # Width of each image in inches\n","image_height = 7.0  # Height of each image in inches\n","display_random_images(directory, image_width, image_height)\n","\n","# Displaying 5 random images of Still class in a row from training data set\n","from PIL import Image\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","\n","def display_random_images(directory, image_width, image_height):\n","    plt.figure(figsize=(image_width, image_height))\n","    plt.suptitle('5 Still Class Random Training Samples', fontsize=12)\n","    image_files = os.listdir(directory)\n","    random.shuffle(image_files)\n","    for i in range(5):\n","        img_path = os.path.join(directory, image_files[i])\n","        img = Image.open(img_path)\n","        plt.subplot(1, 5, i+1)\n","        plt.imshow(img, cmap='gray')  # Specify colormap as 'gray' for grayscale images\n","        plt.title(image_files[i], fontsize=10)\n","        plt.axis('off')\n","    plt.tight_layout()  # Adjust layout to prevent overlap\n","    plt.show()\n","\n","# Display from \"Still\" training directory\n","directory = train_dir_still\n","image_width = 8  # Width of each image in inches\n","image_height = 7.0  # Height of each image in inches\n","display_random_images(directory, image_width, image_height)\n","\n","# Displaying 5 random images of Walking class in a row from training data set\n","from PIL import Image\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","\n","def display_random_images(directory, image_width, image_height):\n","    plt.figure(figsize=(image_width, image_height))\n","    plt.suptitle('5 Walking Class Random Training Samples', fontsize=12)\n","    image_files = os.listdir(directory)\n","    random.shuffle(image_files)\n","    for i in range(5):\n","        img_path = os.path.join(directory, image_files[i])\n","        img = Image.open(img_path)\n","        plt.subplot(1, 5, i+1)\n","        plt.imshow(img, cmap='gray')  # Specify colormap as 'gray' for grayscale images\n","        plt.title(image_files[i], fontsize=10)\n","        plt.axis('off')\n","    plt.tight_layout()  # Adjust layout to prevent overlap\n","    plt.show()\n","\n","# Display from \"Walking\" training directory\n","directory = train_dir_walking\n","image_width = 8  # Width of each image in inches\n","image_height = 7.0  # Height of each image in inches\n","display_random_images(directory, image_width, image_height)"],"metadata":{"id":"5u8_Fx6WBuLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# define reusable data pipeline function\n","def setup_data_pipeline(train_dir, test_dir, validation_split=0.2, batch_size=32, img_height=768, img_width=32, seed=12081970):\n","  # Training dataset configuration\n","  print('Preparing training data set...')\n","  print('Image size used for training ' + str(img_width) + 'x' + str(img_height))\n","  print('Validation split of the training samples ' + str(validation_split*100) + '%')\n","  train_ds = tf.keras.utils.image_dataset_from_directory(\n","      train_dir,\n","      validation_split=validation_split,\n","      subset=\"training\",\n","      seed=seed,\n","      image_size=(img_height, img_width),\n","      batch_size=batch_size\n","  )\n","  print('Done - Preparing training data set.')\n","\n","  # Validation dataset configuration\n","  print('Preparing validation data set...')\n","  val_ds = tf.keras.utils.image_dataset_from_directory(\n","      train_dir,\n","      validation_split=validation_split,\n","      subset=\"validation\",\n","      seed=seed,\n","      image_size=(img_height, img_width),\n","      batch_size=batch_size\n","  )\n","  print('Done - Preparing validation data set.')\n","\n","  # Test dataset configuration\n","  print('Preparing test data set...')\n","  test_ds = tf.keras.utils.image_dataset_from_directory(\n","      test_dir,\n","      seed=seed,\n","      image_size=(img_height, img_width),\n","      batch_size=batch_size\n","  )\n","  print('Done - Preparing test data set.')\n","\n","  # List of inferred class names\n","  class_names = train_ds.class_names\n","  print('List of all training classes:', class_names)\n","\n","  # training batch set info\n","  print('Training set batches information:')\n","  for image_batch, labels_batch in train_ds:\n","    print(image_batch.shape)\n","    print(labels_batch.shape)\n","\n","  # perforance settings - buffered prefetching\n","  print('Setting buffered prefetching the data/images for better execution performance of the program...')\n","  # Performance settings - buffered prefetching\n","  AUTOTUNE = tf.data.AUTOTUNE\n","  train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n","  val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","  test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","  print('Done - Setting buffered pre-fetch.')\n","\n","  return train_ds, val_ds, test_ds, class_names"],"metadata":{"id":"8UBkFHtYl1Ai","executionInfo":{"status":"ok","timestamp":1710475312109,"user_tz":-330,"elapsed":676,"user":{"displayName":"Venkateswar Reddy Melachervu","userId":"09675927748248926857"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# tensorflow dashboard for gradient descent analytics\n","!pip install ngrok\n","!pip install pyngrok\n","\n","import ngrok\n","from pyngrok import ngrok\n","\n","# Set Ngrok authtoken\n","ngrok.set_auth_token(\"2dgXfPL1pbdqUcPXyS5axzhmnrB_4Ux9eRzJVVyUPJD12NEqy\")\n","\n","# Start ngrok\n","# Establish a tunnel to the TensorBoard port\n","public_url = ngrok.connect(addr=\"6006\", bind_tls=True).public_url\n","print(\"TensorBoard URL:\", public_url)\n","ngrok_tunnel = ngrok.connect(addr=\"6006\", bind_tls=True)\n","# Print the public URL where TensorBoard is exposed\n","print(\"TensorBoard URL:\", ngrok_tunnel.public_url)\n","%load_ext tensorboard\n","log_dir = \"logs/fit\"\n","%tensorboard --logdir $log_dir --bind_all"],"metadata":{"id":"5OVEk1qrZ_Ao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normal MLP NN model without any convolution operation\n","# hyper paramters definition\n","batch_size = 32 # to run back propagation epoch\n","img_height = 768\n","img_width = 32\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","\n","# design the model\n","normal_mlp_nn_model_1 = Sequential([\n","  layers.Rescaling(1./255, input_shape=input_shape),\n","  Flatten(input_shape=input_shape),\n","  Dense(128, activation='relu'),\n","  Dense(64, activation='relu'),\n","  Dense(num_classes, activation='softmax')\n","])\n","normal_mlp_nn_model_1._name = 'Normal_MLP_NN_Without_Convolution_And_Original_Image_Resolution_Training_1'\n","\n","# compile the model\n","normal_mlp_nn_model_1.compile(\n","  # Adam optimizer\n","  optimizer='adam',\n","  # # Loss function for classification tasks\n","  loss='sparse_categorical_crossentropy',\n","  # Metric to monitor during training (e.g., accuracy)\n","  metrics=['accuracy'])\n","\n","# let's print the summary of the cnn basic model we built\n","normal_mlp_nn_model_1.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in normal_mlp_nn_model_1.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# let's train the model - 10 epochs\n","\n","import time\n","start_time = time.time()\n","history = normal_mlp_nn_model_1.fit(\n","    train_ds,\n","    validation_data = val_ds,\n","    epochs = epochs\n",")\n","end_time = time.time()\n","training_time = end_time - start_time\n","print(\"Training Time:\", training_time, \"seconds\")\n","\n","# let's plot all graphs to visually understand and evaluate the performance for nomal MLP model\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# plot training and validation accuracy\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training and validation loss\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['loss'], label='Training Loss', color='blue')\n","plt.plot(history.history['val_loss'], label='Validation Loss', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# training time per epoch graph\n","import matplotlib.pyplot as plt\n","\n","# Calculate training time per epoch\n","training_time_per_epoch = (end_time - start_time) / epochs\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"hICiuN2HpVPL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normal MLP NN model without any convolution operation - non-original size image training\n","# hyper paramters definition\n","batch_size = 32 # to run back propagation epoch\n","# img_height = 768\n","# img_width = 32\n","img_height = 50\n","img_width = 5\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","\n","# design the model\n","normal_mlp_nn_model_2 = Sequential([\n","  layers.Rescaling(1./255, input_shape=input_shape),\n","  Flatten(input_shape=input_shape),\n","  Dense(128, activation='relu'),\n","  Dense(64, activation='relu'),\n","  Dense(num_classes, activation='softmax')\n","])\n","normal_mlp_nn_model_2._name = 'Normal_MLP_NN_Without_Convolution_And_Non_Original_Image_Resolution_Training_2'\n","\n","# compile the model\n","normal_mlp_nn_model_2.compile(\n","  # Adam optimizer\n","  optimizer='adam',\n","  # # Loss function for classification tasks\n","  loss='sparse_categorical_crossentropy',\n","  # Metric to monitor during training (e.g., accuracy)\n","  metrics=['accuracy'])\n","\n","# let's print the summary of the cnn basic model we built\n","normal_mlp_nn_model_2.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in normal_mlp_nn_model_2.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# let's train the model - 10 epochs\n","epochs = 10\n","import time\n","start_time = time.time()\n","history = normal_mlp_nn_model_2.fit(\n","    train_ds,\n","    validation_data = val_ds,\n","    epochs = epochs\n",")\n","end_time = time.time()\n","training_time = end_time - start_time\n","print(\"Training Time:\", training_time, \"seconds\")\n","\n","# let's plot all graphs to visually understand and evaluate the performance\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# plot training and validation accuracy\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training and validation loss\n","plt.figure(figsize=(10, 5))\n","plt.plot(history.history['loss'], label='Training Loss', color='blue')\n","plt.plot(history.history['val_loss'], label='Validation Loss', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# training time per epoch graph\n","import matplotlib.pyplot as plt\n","\n","# Calculate training time per epoch\n","training_time_per_epoch = (end_time - start_time) / epochs\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"dHolTuN-0-Sk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN with one hidden layer and RELU activation\n","batch_size = 32 # to run back propagation epoch\n","img_height = 768\n","img_width = 32\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","cnn_model_with_1hl = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","cnn_model_with_1hl._name = 'CNN_with_One_Hidden_Layer_RELU_Activation_with_Original_Image_Trainin_1'\n","\n","# Compile the model\n","cnn_model_with_1hl.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Model details\n","cnn_model_with_1hl.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in cnn_model_with_1hl.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Train the model\n","start_time = time.time()\n","history = cnn_model_with_1hl.fit(train_ds, validation_data=val_ds, epochs=epochs)\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_one_hidden_layer on the test data available in val directory dataset\n","print('Evaluating the model accuracy with test folder data...')\n","test_loss, test_accuracy = cnn_model_with_1hl.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = cnn_model_with_1hl.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"3UxKD0MbezW2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN with one hidden layer and RELU activation with non-original image size\n","batch_size = 32 # to run back propagation epoch\n","img_height = 190\n","img_width = 16\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","cnn_model_with_1hl_2 = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","cnn_model_with_1hl_2._name = 'CNN_with_One_Hidden_Layer_RELU_Activation_with_Non_Original_Image_Training_2'\n","\n","# Compile the model\n","cnn_model_with_1hl_2.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","# Model details\n","cnn_model_with_1hl_2.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in cnn_model_with_1hl_2.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Train the model\n","start_time = time.time()\n","history = cnn_model_with_1hl_2.fit(train_ds, validation_data=val_ds, epochs=epochs)\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_one_hidden_layer on the test data available in val directory dataset\n","print('Evaluating the model accuracy with test folder data...')\n","test_loss, test_accuracy = cnn_model_with_1hl_2.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = cnn_model_with_1hl_2.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"kZdZYlsctAmG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN with multiple hidden layer and RELU activation, 32 filter kernels and visual plots of gradient descent\n","batch_size = 32 # to run back propagation epoch\n","img_height = 768\n","img_width = 32\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","\n","# Let's define log directory for TensorBoard\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","# Let's create TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","\n","cnn_model_with_multiple_hidden_layers_1 = models.Sequential([\n","    layers.Rescaling(1./255, input_shape=input_shape),\n","    layers.Conv2D(32, 3, padding='same', activation='relu'), # filters 32, kernel size 3\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","cnn_model_with_multiple_hidden_layers_1._name = 'CNN_with_Multiple_Hidden_Layers_RELU_Activation_with_Original_Image_Training_1'\n","\n","# Compile the model\n","cnn_model_with_multiple_hidden_layers_1.compile(optimizer='adam',\n","                                  loss='sparse_categorical_crossentropy',\n","                                  metrics=['accuracy'])\n","# Model details\n","cnn_model_with_multiple_hidden_layers_1.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in cnn_model_with_multiple_hidden_layers_1.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Train the model\n","start_time = time.time()\n","history = cnn_model_with_multiple_hidden_layers_1.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[tensorboard_callback])\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_multiple_hidden_layers on the test data available in val directory dataset\n","test_loss, test_accuracy = cnn_model_with_multiple_hidden_layers_1.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = cnn_model_with_multiple_hidden_layers_1.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"qIb7i_eTLVoa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN with multiple hidden layer, RELU activation\n","batch_size = 32 # to run back propagation epoch\n","# img_height = 768\n","# img_width = 32\n","img_height = 390\n","img_width = 16\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","\n","cnn_model_with_multiple_hidden_layers_2 = models.Sequential([\n","    layers.Rescaling(1./255, input_shape=(img_height, img_width,3)),\n","    layers.Conv2D(12, 3, padding='same', activation='relu'), # filters 12, kernel size 3\n","    layers.MaxPooling2D((2, 2),strides=(2, 2), padding='same'),\n","    layers.Conv2D(24, 3, padding='same', activation='relu'),\n","    layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'),\n","    layers.Conv2D(48, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","cnn_model_with_multiple_hidden_layers_2._name = 'CNN_with_Multiple_Hidden_Layers_RELU_Activation_with_Non_Original_Image_Training_2'\n","\n","# Compile the model\n","cnn_model_with_multiple_hidden_layers_2.compile(optimizer='adam',\n","                                  loss='sparse_categorical_crossentropy',\n","                                  metrics=['accuracy'])\n","# Model details\n","cnn_model_with_multiple_hidden_layers_2.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in cnn_model_with_multiple_hidden_layers_2.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Train the model\n","start_time = time.time()\n","history = cnn_model_with_multiple_hidden_layers_2.fit(train_ds, validation_data=val_ds, epochs=epochs)\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_multiple_hidden_layers on the test data available in val directory dataset\n","test_loss, test_accuracy = cnn_model_with_multiple_hidden_layers_2.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = cnn_model_with_multiple_hidden_layers_2.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"AOhSmJwsilHT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN with multiple hidden layer, RELU activation with gradient descent data visualization\n","# For visualizing gradient descent data we will use TensorBoard\n","\n","from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","\n","# Let's define a log directory for TensorBoard\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","\n","# Let's create TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","batch_size = 32 # to run back propagation epoch\n","# img_height = 768\n","# img_width = 32\n","img_height = 390\n","img_width = 16\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = len(class_names)\n","input_shape = (img_height,img_width, 3)\n","\n","cnn_model_with_multiple_hidden_layers_gdv_3 = models.Sequential([\n","    layers.Rescaling(1./255, input_shape=(img_height, img_width,3)),\n","    layers.Conv2D(12, 3, padding='same', activation='relu'), # filters 12, kernel size 3\n","    layers.MaxPooling2D((2, 2),strides=(2, 2), padding='same'),\n","    layers.Conv2D(24, 3, padding='same', activation='relu'),\n","    layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'),\n","    layers.Conv2D(48, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","cnn_model_with_multiple_hidden_layers_gdv_3._name = 'CNN_with_Multiple_Hidden_Layers_RELU_Activation_with_Non_Original_Image_Training_GDV_3'\n","\n","# Compile the model\n","cnn_model_with_multiple_hidden_layers_gdv_3.compile(optimizer='adam',\n","                                  loss='sparse_categorical_crossentropy',\n","                                  metrics=['accuracy'])\n","# Model details\n","cnn_model_with_multiple_hidden_layers_gdv_3.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in cnn_model_with_multiple_hidden_layers_gdv_3.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Train the model\n","start_time = time.time()\n","history = cnn_model_with_multiple_hidden_layers_gdv_3.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[tensorboard_callback])\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_multiple_hidden_layers on the test data available in val directory dataset\n","test_loss, test_accuracy = cnn_model_with_multiple_hidden_layers_gdv_3.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = cnn_model_with_multiple_hidden_layers_gdv_3.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"-H6CF9pb-sLo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN with multiple hidden layer, RELU activation, and non-original image size for training set with gdv\n","\n","from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","\n","# Let's define a log directory for TensorBoard\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","# Let's create TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# let's train with original image sizes\n","i_height = 768\n","i_width = 32\n","val_split = 0.2\n","seed=12081970\n","b_size = 32\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, val_split, i_width, i_height, b_size, seed)\n","num_classes = len(class_names)\n","input_shape = (i_height,i_width, 3)\n","epochs = 10\n","\n","cnn_model_with_multiple_hidden_layers_4 = models.Sequential([\n","    layers.Rescaling(1./255, input_shape=input_shape),\n","    layers.Conv2D(12, 3, padding='same', activation='relu'), # filters 12, kernel size 3\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(24, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","cnn_model_with_multiple_hidden_layers_4._name = 'CNN_with_Multiple_Hidden_Layers_RELU_Activation_with_Original_Image_Size_Training_4'\n","\n","# Compile the model\n","cnn_model_with_multiple_hidden_layers_4.compile(optimizer='adam',\n","                                  loss='sparse_categorical_crossentropy',\n","                                  metrics=['accuracy'])\n","# Model details\n","cnn_model_with_multiple_hidden_layers_4.summary()\n","# Print activation functions\n","print(\"Activation Functions:\")\n","for layer in cnn_model_with_multiple_hidden_layers_4.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Train the model\n","start_time = time.time()\n","history = cnn_model_with_multiple_hidden_layers_4.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[tensorboard_callback])\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_multiple_hidden_layers on the test data available in val directory dataset\n","test_loss, test_accuracy = cnn_model_with_multiple_hidden_layers_4.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = cnn_model_with_multiple_hidden_layers_4.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"],"metadata":{"id":"4VuQ_JSgjO3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pre-trained ResNet model with gradient descent data visualization\n","\n","# install necessary modules\n","!pip install tensorflow==2.12.0\n","!pip install tensorflow-datasets==4.8.0\n","\n","# imports for Resnet50\n","import tensorflow_datasets as tfds\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n","from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.preprocessing import image\n","\n","# For visualizing gradient descent data we will use TensorBoard\n","from tensorflow.keras.callbacks import TensorBoard\n","import datetime\n","# Let's define a log directory for TensorBoard\n","log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","# Let's create TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","\n","# Hyper parameters\n","batch_size = 32 # to run back propagation epoch\n","img_height = 768\n","img_width = 32\n","# img_height = 390\n","# img_width = 16\n","validation_split=0.2\n","seed=12081970\n","epochs = 10\n","\n","# prepare up train and validation data sets\n","train_ds, val_ds, test_ds, class_names = setup_data_pipeline(train_dir, val_dir, validation_split, batch_size, img_height, img_width, seed)\n","num_classes = 3\n","input_shape = (img_height,img_width, 3)\n","\n","# Due to repeat of data for training, we need to set the number of steps manually\n","total_samples = len(list(train_ds))\n","train_steps_per_epoch = total_samples # this is batch size\n","val_steps_per_epoch = total_samples # for valaidation\n","print('Length of the train data set is ' + str(train_steps_per_epoch))\n","print('Length of the validation data set is ' + str(val_steps_per_epoch))\n","\n","# Load ResNet50 pretrained model without the top classification layer\n","print('Configuring ResNet50 with input shape of ' + str(img_width) + 'x' + str(img_height))\n","base_model = ResNet50(weights='imagenet', include_top=False)\n","# Freeze the base model layers\n","base_model.trainable = False\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","predictions = Dense(num_classes, activation='softmax')(x)\n","\n","# Create the full model\n","gpr_object_classify_resnet50_model_1 = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile the model\n","for layer in base_model.layers:\n","  layer.trainable = False\n","  gpr_object_classify_resnet50_model_1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","\n","gpr_object_classify_resnet50_model_1.compile(\n","    optimizer = 'adam',\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n","    metrics = ['accuracy']\n",")\n","gpr_object_classify_resnet50_model_1._name = 'ResNet50_with_Original_Image_Training_GDV_1'\n","\n","# adapted resnet50 model summary\n","gpr_object_classify_resnet50_model_1.summary()\n","print(\"Activation Functions:\")\n","for layer in gpr_object_classify_resnet50_model_1.layers:\n","    if hasattr(layer, 'activation'):\n","        print(layer.name, \"-\", layer.activation.__name__)\n","    else:\n","        print(layer.name, \"- No activation\")\n","\n","# Set up TensorBoard callback\n","tensorboard_callback = TensorBoard(log_dir='./logs', histogram_freq=1)\n","\n","# Train the model\n","# let's ensure not to run out of training data\n","train_ds = train_ds.repeat()\n","val_ds = val_ds.repeat()\n","\n","print('Training the ResNet50 with training data...')\n","start_time = time.time()\n","history = gpr_object_classify_resnet50_model_1.fit(\n","    train_ds,\n","    steps_per_epoch=train_steps_per_epoch,\n","    validation_data = val_ds,\n","    validation_steps=val_steps_per_epoch,\n","    epochs = epochs,\n","    callbacks=[tensorboard_callback])\n","end_time = time.time()\n","training_time_per_epoch = (end_time - start_time) / epochs\n","print('Done - Training the ResNet50 with training data.')\n","print(\"Training Time Per Epoch:\", training_time_per_epoch, \"seconds\")\n","\n","# Convert accuracy values to percentage\n","train_accuracy_percentage = [acc * 100 for acc in history.history['accuracy']]\n","val_accuracy_percentage = [acc * 100 for acc in history.history['val_accuracy']]\n","\n","# Plot accuracy versus epoch in percentage\n","plt.plot(train_accuracy_percentage, label='Training Accuracy', color='blue')\n","plt.plot(val_accuracy_percentage, label='Validation Accuracy', color='green')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Training and Validation Accuracy')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Plot training time per epoch\n","plt.plot(range(1, epochs + 1), [training_time_per_epoch] * epochs, label='Training Time per Epoch', color='blue')\n","plt.xlabel('Epoch')\n","plt.ylabel('Training Time (seconds)')\n","plt.title('Training Time per Epoch')\n","plt.legend()\n","plt.grid(True)\n","plt.show()\n","\n","# Evaluate the cnn_model_with_multiple_hidden_layers on the test data available in val directory dataset\n","test_loss, test_accuracy = gpr_object_classify_resnet50_model_1.evaluate(test_ds)\n","\n","# Plot accuracy in percentage\n","print(\"Test Accuracy:\", test_accuracy * 100, \"%\")\n","\n","# Predict labels for the test dataset\n","test_predictions = gpr_object_classify_resnet50_model_1.predict(test_ds)\n","test_labels = np.concatenate([labels for _, labels in test_ds], axis=0)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(test_labels, np.argmax(test_predictions, axis=1))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","\n","# Plot confusion matrix\n","plt.figure(figsize=(10, 8))\n","disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()\n","%tensorboard --logdir logs"],"metadata":{"id":"Ofk7Het2pEu7"},"execution_count":null,"outputs":[]}]}